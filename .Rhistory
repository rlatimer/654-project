step_rm(c('date','month'))
View(blueprint_oregon %>% prep() %>% summary)
set.seed(12012021)  # for reproducibility
loc      <- sample(1:nrow(oregon), round(nrow(oregon) * 0.8))
ordata_train  <- oregon[loc, ]
ordata_test  <- oregon[-loc, ]
View(oregon)
View(ordata_train)
View(oregon)
folds = cut(seq(1,nrow(ordata_train)),breaks=10,labels=FALSE)
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices,
classProbs = TRUE,
summaryFunction = mnLogLoss)
grid <- expand.grid(mtry = 27,splitrule='variance',min.node.size=2)
grid
or_baggedtrees <- caret::train(blueprint_oregon,
data      = ordata_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
metric = 'logLoss',
num.trees = 500,
max.depth = 60)
View(ordata_train)
cv <- trainControl(method = "cv",
index  = my.indices)
grid <- expand.grid(mtry = 27,splitrule='variance',min.node.size=2)
grid
or_baggedtrees <- caret::train(blueprint_oregon,
data      = ordata_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
metric = 'logLoss',
num.trees = 500,
max.depth = 60)
or_baggedtrees <- caret::train(blueprint_oregon,
data      = ordata_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 500,
max.depth = 60)
View(or_baggedtrees)
or_baggedtrees$times
ordata_predict_test <- predict(or_baggedtrees, ordata_test)
bag_rmse <- sqrt(mean((ordata_test$target - ordata_predict_test)^2))
bag_rmse
cv   <- trainControl(method = "cv")
grid <- expand.grid(mtry = 27,splitrule='variance',min.node.size=2)
grid
or_baggedtrees <- caret::train(blueprint_oregon,
data      = ordata_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 500,
max.depth = 60)
ordata_predict_test <- predict(or_baggedtrees, ordata_test)
bag_rmse <- sqrt(mean((ordata_test$target - ordata_predict_test)^2))
bag_rmse
View(ordata_test)
readability <- read.csv('https://raw.githubusercontent.com/uo-datasci-specialization/c4-ml-fall-2021/main/data/readability_features.csv',header=TRUE)
View(readability)
ordata_predict_test <- predict(or_baggedtrees, ordata_test)
bag_rmse <- sqrt(mean((ordata_test$score - ordata_predict_test)^2))
bag_rmse
#calculate MAE for bagged tree model
orpredicted_te <- predict(or_baggedtrees[[500]], ordata_test)
orpredicted_te <- predict(or_baggedtrees, ordata_test)
bag_mae <- mean(abs(ordata_test$score - orpredicted_te))
bag_mae
bag_rsqd <- cor(ordata_test$score,orpredicted_te)^2
bag_rsqd
folds = cut(seq(1,nrow(tweet_tr)),breaks=10,labels=FALSE)
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices,
classProbs = TRUE,
summaryFunction = mnLogLoss)
grid <- expand.grid(mtry = 250,splitrule='gini',min.node.size=2)
grid
rfs_tweet <- caret::train(blueprint_tweet,
data = tweet_tr,
method = 'ranger',
trControl = cv,
tuneGrid = grid,
metric = 'logLoss',
num.trees = 500,
max.depth = 60)
logLoss_rfs <- rfs_tweet$results$logLoss
logLoss_bags <- bags_tweet$results$logLoss
tweet_predicted_te_bags <- predict(bags_tweet, tweet_te, type='prob')
tweet_predicted_te_rfs <- predict(rfs_tweet, tweet_te, type='prob')
require(cutpointr)
cut.obj_bags <- cutpointr(x     = tweet_predicted_te_bags$Positive,
class = tweet_te$sentiment)
auc(cut.obj_bags)
cut.obj_rfs <- cutpointr(x     = tweet_predicted_te_rfs$Positive,
class = tweet_te$sentiment)
auc(cut.obj_rfs)
pred_class_bags <- ifelse(tweet_predicted_te_bags$Positive>.5,1,0)
confusion_bags <- table(tweet_te$sentiment,pred_class_bags)
confusion_bags
#random forest
pred_class_rfs <- ifelse(tweet_predicted_te_rfs$Positive>.5,1,0)
confusion_rfs <- table(tweet_te$sentiment,pred_class_rfs)
confusion_rfs
# True Negative Rate
#bagged trees
confusion_bags[1,1]/(confusion_bags[1,1]+confusion_bags[1,2])
#random forest
confusion_rfs[1,1]/(confusion_rfs[1,1]+confusion_rfs[1,2])
# False Positive Rate
#bagged trees
confusion_bags[1,2]/(confusion_bags[1,1]+confusion_bags[1,2])
#random forest
confusion_rfs[1,2]/(confusion_rfs[1,1]+confusion_rfs[1,2])
# True Positive Rate
#bagged trees
confusion_bags[2,2]/(confusion_bags[2,1]+confusion_bags[2,2])
#random forest
confusion_rfs[2,2]/(confusion_rfs[2,1]+confusion_rfs[2,2])
# Precision
#bagged trees
confusion_bags[2,2]/(confusion_bags[1,2]+confusion_bags[2,2])
#random forest
confusion_rfs[2,2]/(confusion_rfs[1,2]+confusion_rfs[2,2])
ll_bags <- bags_tweet$results$logLoss
ll_rfs <- rfs_tweet$results$logLoss
#checking bagged tree model on the test dataset
tweet_predicted_te_bags <- predict(bags_tweet, tweet_te, type='prob')
tweet_predicted_te_rfs <- predict(rfs_tweet, tweet_te, type='prob')
cut.obj_bags <- cutpointr(x     = tweet_predicted_te_bags$Positive,
class = tweet_te$sentiment)
auc_bags<-auc(cut.obj_bags)
cut.obj_rfs <- cutpointr(x     = tweet_predicted_te_rfs$Positive,
class = tweet_te$sentiment)
auc_rfs<-auc(cut.obj_rfs)
pred_class_bags <- ifelse(tweet_predicted_te_bags$Positive>.5,1,0)
confusion_bags <- table(tweet_te$sentiment,pred_class_bags)
#random forest
pred_class_rfs <- ifelse(tweet_predicted_te_rfs$Positive>.5,1,0)
confusion_rfs <- table(tweet_te$sentiment,pred_class_rfs)
tnr_bags<-confusion_bags[1,1]/(confusion_bags[1,1]+confusion_bags[1,2])
#random forest
tnr_rfs<-confusion_rfs[1,1]/(confusion_rfs[1,1]+confusion_rfs[1,2])
# True Positive Rate
#bagged trees
tpr_bags<-confusion_bags[2,2]/(confusion_bags[2,1]+confusion_bags[2,2])
#random forest
tpr_rfs<-confusion_rfs[2,2]/(confusion_rfs[2,1]+confusion_rfs[2,2])
# Precision
#bagged trees
pre_bags<-confusion_bags[2,2]/(confusion_bags[1,2]+confusion_bags[2,2])
pre_rfs<-confusion_rfs[2,2]/(confusion_rfs[1,2]+confusion_rfs[2,2])
bag <- data.frame(Model = c("Bagged Trees"),
LL = c(ll_bags),
AUC = c(auc_bags),
ACC = c(acc_bags),
TPR = c(tpr_bags),
TNR = c(tnr_bags),
PRE = c(pre_bags))
acc_bags(confusion_bags[2,2]+confusion_bags[1,1])/
(confusion_bags[2,2]+confusion_bags[1,1]+confusion_bags[1,2]+confusion_bags[2,2])
#random forest
acc_rfs(confusion_rfs[2,2]+confusion_rfs[1,1])/
(confusion_rfs[2,2]+confusion_rfs[1,1]+confusion_rfs[1,2]+confusion_rfs[2,2])
acc_bags<-(confusion_bags[2,2]+confusion_bags[1,1])/
(confusion_bags[2,2]+confusion_bags[1,1]+confusion_bags[1,2]+confusion_bags[2,2])
#random forest
acc_rfs<-(confusion_rfs[2,2]+confusion_rfs[1,1])/
(confusion_rfs[2,2]+confusion_rfs[1,1]+confusion_rfs[1,2]+confusion_rfs[2,2])
bag <- data.frame(Model = c("Bagged Trees"),
LL = c(ll_bags),
AUC = c(auc_bags),
ACC = c(acc_bags),
TPR = c(tpr_bags),
TNR = c(tnr_bags),
PRE = c(pre_bags))
rfs <- data.frame(Model = c("Random Forests Model"),
LL = c(ll_rfs),
AUC = c(auc_rfs),
ACC = c(acc_rfs),
TPR = c(tpr_rfs),
TNR = c(tnr_rfs),
PRE = c(pre_rfs))
Table1 <- rbind(bagmod, ranmod)
Table1 <- rbind(bag, rfs)
Table1
# Load the following packages needed for modeling in this assignment
require(caret)
require(recipes)
require(ranger)
# Import the oregon dataset
oregon <- read.csv('https://raw.githubusercontent.com/uo-datasci-specialization/c4-ml-fall-2021/main/content/post/hw2/data/hw1_oregon_final.csv',header=TRUE)
# Recipe for the oregon dataset
outcome <- 'score'
id      <- 'id'
categorical <- c('sex','ethnic_cd','tst_bnch','migrant_ed_fg','ind_ed_fg',
'sp_ed_fg','tag_ed_fg','econ_dsvntg','stay_in_dist',
'stay_in_schl','dist_sped','trgt_assist_fg',
'ayp_dist_partic','ayp_schl_partic','ayp_dist_prfrm',
'ayp_schl_prfrm','rc_dist_partic','rc_schl_partic',
'rc_dist_prfrm','rc_schl_prfrm','grp_rpt_dist_partic',
'grp_rpt_schl_partic','grp_rpt_dist_prfrm',
'grp_rpt_schl_prfrm')
numeric <- c('enrl_grd')
cyclic <- c('date','month')
blueprint_oregon <- recipe(x     = oregon,
vars  = c(outcome,categorical,numeric,cyclic),
roles = c('outcome',rep('predictor',27))) %>%
step_indicate_na(all_of(categorical),all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_harmonic('date',frequency=1,cycle_size=31,role='predictor') %>%
step_harmonic('month',frequency=1,cycle_size=12,role='predictor') %>%
step_ns('enrl_grd',deg_free=3) %>%
step_normalize(c(paste0(numeric,'_ns_1'),paste0(numeric,'_ns_2'),paste0(numeric,'_ns_3'))) %>%
step_normalize(c("date_sin_1","date_cos_1","month_sin_1","month_cos_1")) %>%
step_dummy(all_of(categorical),one_hot=TRUE) %>%
step_rm(c('date','month'))
View(blueprint_oregon %>% prep() %>% summary)
set.seed(12012021)  # for reproducibility
loc      <- sample(1:nrow(oregon), round(nrow(oregon) * 0.8))
ordata_train  <- oregon[loc, ]
ordata_test  <- oregon[-loc, ]
cv <- trainControl(method = "none")
grid <- expand.grid(mtry = 27,splitrule='variance',min.node.size=2)
grid
or_baggedtrees <- caret::train(blueprint_oregon,
data      = ordata_train,
method    = 'ranger',
trControl = cv,
tuneGrid  = grid,
num.trees = 500,
max.depth = 60)
ordata_predict_test <- predict(or_baggedtrees, ordata_test)
#calculate RMSE for bagged tree model
bag_rmse <- sqrt(mean((ordata_test$score - ordata_predict_test)^2))
bag_rmse
#for some reason, this is coming up NaN
#calculate MAE for bagged tree model
orpredicted_te <- predict(or_baggedtrees, ordata_test)
bag_mae <- mean(abs(ordata_test$score - orpredicted_te))
bag_mae
#calculate rsqd for bagged tree model
bag_rsqd <- cor(ordata_test$score,orpredicted_te)^2
bag_rsqd
setwd("~/personal/EDLD MS/EDLD 654 DS/654-project")
initial <- import(here("data", "aac_intakes_outcomes.csv")) %>%
clean_names() %>%
as_tibble()
library(tidyverse)
initial <- import(here("data", "aac_intakes_outcomes.csv")) %>%
clean_names() %>%
as_tibble()
library(janitor)
install.packages("janitor")
library(janitor)
initial <- import(here("data", "aac_intakes_outcomes.csv")) %>%
clean_names() %>%
as_tibble()
initial <- read.csv(C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654-project/data/aac_intakes_outcomes.csv")
initial <- read.csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654-project/data/aac_intakes_outcomes.csv")
read.csv?
?read.csv
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654-project/data/aac_intakes_outcomes.csv")
library(tidyverse)
library(janitor)
library(here)
setwd("~/personal/EDLD MS/EDLD 654 DS/654-project")
setwd("~/personal/EDLD MS/EDLD 654 DS/project")
initial <- import(here("data", "aac_intakes_outcomes.csv")) %>%
clean_names() %>%
as_tibble()
initial <- here("data", "aac_intakes_outcomes.csv")) %>%
clean_names() %>%
as_tibble()
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654-project/data/aac_intakes_outcomes.csv")
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654project/data/aac_intakes_outcomes.csv")
setwd("~/personal/EDLD MS/EDLD 654 DS/654project")
library(tidyverse)
library(janitor)
library(here)
initial <- import(here("data", "aac_intakes_outcomes.csv")) %>%
clean_names() %>%
as_tibble()
import?
?import
?here
View(initial)
initial <- read.csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654project/data/aac_intakes_outcomes.csv", header=TRUE)
require(readr)
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654project/data/aac_intakes_outcomes.csv", header=TRUE)
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654project/data/aac_intakes_outcomes.csv")
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/654project/data/aac_intakes_outcomes.csv")
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/
654project/data/aac_intakes_outcomes.csv")
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/654project/data/aac_intakes_outcomes.csv")
View(initial)
require(caret)
require(recipes)
require(finalfit)
require(glmnet)
missing <- ff_glimpse(initial)$Continuous
head(missing)
flag_na <- which(as.numeric(missing$missing_percent) > 75)
flag_na
missing
missing <- ff_glimpse(initial)
missing
initial <- read_csv("C:/Users/rlatimer/Documents/personal/EDLD MS/EDLD 654 DS/654project/data/aac_intakes_outcomes.csv")
View(initial)
missing <- ff_glimpse(initial)
missing
View(missing)
View(initial)
#removing variables above 75%
clean_initial <- initial %>%
select(animal_id_outcome,animal_id_outcome,outcome_type,sex_upon_outcome,age_upon_outcome_days,
outcome_month, outcome_year, animal_type,breed,intake_condition,intake_type,
sex_upon_intake,age_upon_intake_days,intake_month,intake_year,time_in_shelter_days)
View(oregon)
clean_initial <- initial %>%
select(animal_id_outcome,animal_id_outcome,outcome_type,sex_upon_outcome,
outcome_month, outcome_year, animal_type,breed,intake_condition,intake_type,
sex_upon_intake,age_upon_intake_years,intake_month,intake_year,time_in_shelter_days)
clean_initial <- initial %>%
select(animal_id_outcome,outcome_type,sex_upon_outcome,
outcome_month, animal_type,breed,intake_condition,intake_type,
sex_upon_intake,age_upon_intake_years,intake_month,time_in_shelter_days)
outcome <- 'time_in_shelter_days'
id      <- 'animal_id_outcome'
categorical <- c('outcome_type','sex_upon_outcome','animal_type','breed','intake_condition',
'intake_type','sex_upon_intake')
numeric <- c('age_upon_intake_years')
cyclic <- c('outcome_month','intake_month')
blueprint_aac <- recipe(x     = clean_initial,
vars  = c(outcome,categorical,numeric,cyclic),
roles = c('outcome',rep('predictor',10))) %>%
step_indicate_na(all_of(categorical),all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_harmonic('intake_month',frequency=1,cycle_size=12,role='predictor') %>%
step_harmonic('outcome_month',frequency=1,cycle_size=12,role='predictor') %>%
step_ns('age_upon_intake_years',deg_free=3) %>%
step_normalize(c(paste0(numeric,'_ns_1'),paste0(numeric,'_ns_2'),paste0(numeric,'_ns_3'))) %>%
step_normalize(c("outcome_month_sin_1","outcome_month_cos_1","intake_month_sin_1","intake_month_cos_1")) %>%
step_dummy(all_of(categorical),one_hot=TRUE) %>%
step_rm(c('outcome_month','intake_month'))
View(blueprint_aac %>% prep() %>% summary)
aac <- initial %>%
select(animal_id_outcome,outcome_type,sex_upon_outcome,
outcome_month, animal_type,breed,intake_condition,intake_type,
sex_upon_intake,age_upon_intake_years,intake_month,time_in_shelter_days)
View(aac)
set.seed(12042021)  # for reproducibility
loc      <- sample(1:nrow(aac), round(nrow(aac) * 0.8))
aac_train  <- oregon[loc, ]
aac_test  <- oregon[-loc, ]
aac_train = aac_train[sample(nrow(aac_train)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(aac_train)),breaks=10,labels=FALSE)
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
#Ridge
grid <- data.frame(alpha = 0, lambda = seq(0.01,3,.01))
#grid
ridge <- caret::train(blueprint_aac,
data      = aac_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
View(aac_train)
aac_train  <- aac[loc, ]
aac_test  <- aac[-loc, ]
# Randomly shuffle the data
aac_train = aac_train[sample(nrow(aac_train)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(aac_train)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
#Ridge
grid <- data.frame(alpha = 0, lambda = seq(0.01,3,.01))
ridge <- caret::train(blueprint_aac,
data      = aac_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
grid <- data.frame(alpha = 0, lambda = seq(0.01,3,.05))
ridge <- caret::train(blueprint_aac,
data      = aac_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
ridge$bestTune
View(oregon)
x <- initial$breed
strsplit(x,'/')
initial$breed1 <- (sapply(strsplit(x,'/'),`[`,1))
View(initial)
#keeping desired variables
aac <- initial %>%
select(animal_id_outcome,outcome_type,sex_upon_outcome,
outcome_month, animal_type,breed,intake_condition,intake_type,
sex_upon_intake,age_upon_intake_years,intake_month,time_in_shelter_days)
aac <- initial %>%
select(animal_id_outcome,outcome_type,sex_upon_outcome,
outcome_month, animal_type,breed1,intake_condition,intake_type,
sex_upon_intake,age_upon_intake_years,intake_month,time_in_shelter_days)
outcome <- 'time_in_shelter_days'
id      <- 'animal_id_outcome'
categorical <- c('outcome_type','sex_upon_outcome','animal_type','breed1','intake_condition',
'intake_type','sex_upon_intake')
numeric <- c('age_upon_intake_years')
cyclic <- c('outcome_month','intake_month')
blueprint_aac <- recipe(x     = clean_initial,
vars  = c(outcome,categorical,numeric,cyclic),
roles = c('outcome',rep('predictor',10))) %>%
step_indicate_na(all_of(categorical),all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_harmonic('intake_month',frequency=1,cycle_size=12,role='predictor') %>%
step_harmonic('outcome_month',frequency=1,cycle_size=12,role='predictor') %>%
step_ns('age_upon_intake_years',deg_free=3) %>%
step_normalize(c(paste0(numeric,'_ns_1'),paste0(numeric,'_ns_2'),paste0(numeric,'_ns_3'))) %>%
step_normalize(c("outcome_month_sin_1","outcome_month_cos_1","intake_month_sin_1","intake_month_cos_1")) %>%
step_dummy(all_of(categorical),one_hot=TRUE) %>%
step_rm(c('outcome_month','intake_month'))
blueprint_aac <- recipe(x     = aac,
vars  = c(outcome,categorical,numeric,cyclic),
roles = c('outcome',rep('predictor',10))) %>%
step_indicate_na(all_of(categorical),all_of(numeric)) %>%
step_zv(all_numeric()) %>%
step_impute_mean(all_of(numeric)) %>%
step_impute_mode(all_of(categorical)) %>%
step_harmonic('intake_month',frequency=1,cycle_size=12,role='predictor') %>%
step_harmonic('outcome_month',frequency=1,cycle_size=12,role='predictor') %>%
step_ns('age_upon_intake_years',deg_free=3) %>%
step_normalize(c(paste0(numeric,'_ns_1'),paste0(numeric,'_ns_2'),paste0(numeric,'_ns_3'))) %>%
step_normalize(c("outcome_month_sin_1","outcome_month_cos_1","intake_month_sin_1","intake_month_cos_1")) %>%
step_dummy(all_of(categorical),one_hot=TRUE) %>%
step_rm(c('outcome_month','intake_month'))
View(blueprint_aac %>% prep() %>% summary)
#splitting data for testing and training
set.seed(12042021)  # for reproducibility
loc      <- sample(1:nrow(aac), round(nrow(aac) * 0.8))
aac_train  <- aac[loc, ]
aac_test  <- aac[-loc, ]
aac_train = aac_train[sample(nrow(aac_train)),]
# Create 10 folds with equal size
folds = cut(seq(1,nrow(aac_train)),breaks=10,labels=FALSE)
# Create the list for each fold
my.indices <- vector('list',10)
for(i in 1:10){
my.indices[[i]] <- which(folds!=i)
}
cv <- trainControl(method = "cv",
index  = my.indices)
#Ridge
grid <- data.frame(alpha = 0, lambda = seq(0.01,3,.05))
#grid
ridge <- caret::train(blueprint_aac,
data      = aac_train,
method    = "glmnet",
trControl = cv,
tuneGrid  = grid)
ridge$bestTune
predict_te_ridge <- predict(ridge, aac_test)
r_rsq_te <- cor(aac_test$time_in_shelter_days,predict_te_ridge)^2
r_rsq_te
r_mae_te <- mean(abs(aac_test$time_in_shelter_days - predict_te_ridge))
r_mae_te
r_rmse_te <- sqrt(mean((aac_test$time_in_shelter_days - predict_te_ridge)^2))
r_rmse_te
coefs <- coef(ridge$finalModel,
ridge$bestTune$lambda)
coefs.zero <- coefs[which(coefs[,1]==0),]
length(coefs.zero)
coefs.nonzero <- coefs[which(coefs[,1]!=0),]
length(coefs.nonzero)
ind   <- order(abs(coefs.nonzero),decreasing=T)
head(as.matrix(coefs.nonzero[ind[-1]]),10)
